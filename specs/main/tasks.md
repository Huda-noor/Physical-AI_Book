# Tasks: Phase 2 RAG Chatbot Implementation

**Input**: Design documents from `/specs/main/`
**Prerequisites**: plan.md (complete), spec.md (complete)

**Tests**: Tests are NOT included in this task list as they were not explicitly requested in the feature specification. Implementation focuses on functional delivery.

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

**Status**: Implementation already complete - This task list documents what was built for traceability.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3, US4)
- Include exact file paths in descriptions

## Path Conventions

- **Web app structure**: `backend/` and `website/` at repository root
- Backend: Python/FastAPI in `backend/app/`
- Frontend: React/Docusaurus in `website/src/`

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization and basic structure

- [x] T001 Create backend/ directory structure with FastAPI project layout
- [x] T002 Initialize Python project with requirements.txt (FastAPI, OpenAI, Qdrant, psycopg2)
- [x] T003 [P] Create backend/.env.example with configuration template
- [x] T004 [P] Create backend/schema.sql for Neon PostgreSQL database schema
- [x] T005 [P] Create backend/README.md with setup instructions

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented

**‚ö†Ô∏è CRITICAL**: No user story work can begin until this phase is complete

- [x] T006 Create backend/app/config.py for settings management (Pydantic Settings)
- [x] T007 Create backend/app/schemas.py with Pydantic models (ChatQueryRequest, ChatQueryResponse, SourceCitation, ChunkMetadata)
- [x] T008 [P] Implement backend/app/services/openai_service.py (embeddings + GPT-4o-mini client)
- [x] T009 [P] Implement backend/app/services/qdrant_service.py (vector operations, collection management)
- [x] T010 [P] Implement backend/app/services/neon_service.py (PostgreSQL connection pool, metadata CRUD)
- [x] T011 Implement backend/app/services/rag_service.py (RAG pipeline orchestration)
- [x] T012 [P] Create backend/app/api/health.py (health check endpoint for all services)
- [x] T013 Create backend/app/main.py (FastAPI application with CORS, rate limiting, lifespan management)
- [x] T014 [P] Create website/src/hooks/useChatbot.ts (React hook for chat state management)
- [x] T015 [P] Create website/src/components/ChatbotIcon.tsx (floating action button component)
- [x] T016 [P] Create website/src/components/ChatbotModal.tsx (modal interface component)

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel

---

## Phase 3: User Story 1 - Ask General Question (Priority: P1) üéØ MVP

**Goal**: Enable students to ask questions about any textbook topic and receive answers with source citations from the entire book (full-book mode)

**Independent Test**:
1. Open chatbot on any page
2. Ask "What is Physical AI?"
3. Verify answer is returned with sources citing Chapter 1
4. Check sources show chapter number, section title, and relevance score

### Implementation for User Story 1

- [x] T017 [P] [US1] Create backend/app/ingest_textbook.py (document ingestion pipeline)
- [x] T018 [P] [US1] Implement markdown parsing in ingest_textbook.py (extract chapters, sections, content)
- [x] T019 [US1] Implement text chunking in ingest_textbook.py (800 chars with 200 overlap)
- [x] T020 [US1] Implement batch embedding generation in ingest_textbook.py (OpenAI API integration)
- [x] T021 [US1] Implement vector storage in ingest_textbook.py (Qdrant upsert with metadata)
- [x] T022 [US1] Implement metadata storage in ingest_textbook.py (Neon PostgreSQL insert)
- [x] T023 [US1] Create backend/app/api/query.py (POST /api/query endpoint)
- [x] T024 [US1] Implement full-book query mode in rag_service.py (embedding ‚Üí vector search ‚Üí metadata ‚Üí GPT-4o-mini)
- [x] T025 [US1] Add rate limiting to query endpoint (SlowAPI, 10 req/min per IP)
- [x] T026 [US1] Add source citation formatting in query response
- [x] T027 [US1] Update website/src/components/RAGChatbot.tsx to call backend API
- [x] T028 [US1] Implement message display with source citations in ChatbotModal.tsx
- [x] T029 [US1] Add loading states and error handling in useChatbot.ts

**Checkpoint**: At this point, User Story 1 should be fully functional - students can ask questions and get answers with sources from the entire textbook

---

## Phase 4: User Story 2 - Ask About Selected Text (Priority: P2)

**Goal**: Enable students to ask questions about specific text they've highlighted, getting explanations focused on that exact content only

**Independent Test**:
1. Highlight a paragraph on any chapter page
2. Open chatbot and verify "Text selected" indicator appears
3. Ask "Explain this in simpler terms"
4. Verify answer uses only the highlighted text as context (no full-book search)
5. Clear selection and verify indicator disappears

### Implementation for User Story 2

- [x] T030 [US2] Add selected_text parameter to ChatQueryRequest schema in backend/app/schemas.py
- [x] T031 [US2] Implement selected-text mode in rag_service.py (skip vector search, direct GPT-4o-mini)
- [x] T032 [US2] Update backend/app/api/query.py to handle selected_text parameter
- [x] T033 [US2] Add text selection detection to website/src/components/RAGChatbot.tsx (window.getSelection() event listener)
- [x] T034 [US2] Create selected-text indicator UI in RAGChatbot.tsx (shows character count, clear button)
- [x] T035 [US2] Pass selected text to API in callRAGAPI function
- [x] T036 [US2] Clear selected text after query submission
- [x] T037 [US2] Handle selected text in GPT-4o-mini prompt in openai_service.py

**Checkpoint**: At this point, User Stories 1 AND 2 should both work independently - full-book mode and selected-text mode

---

## Phase 5: User Story 3 - Navigate with Chat History (Priority: P3)

**Goal**: Enable students to keep their chat history as they navigate between chapters, maintaining conversation context

**Independent Test**:
1. Ask a question on Chapter 1 page
2. Navigate to Chapter 3 page
3. Open chatbot
4. Verify previous conversation is still visible
5. Ask another question
6. Navigate back to Chapter 1
7. Verify both messages persist

### Implementation for User Story 3

- [x] T038 [US3] Add session management to useChatbot.ts (generate/retrieve session ID from localStorage)
- [x] T039 [US3] Implement chat history persistence in useChatbot.ts (save messages to localStorage after each message)
- [x] T040 [US3] Implement chat history loading in useChatbot.ts (restore messages on component mount)
- [x] T041 [US3] Add clear chat functionality in RAGChatbot.tsx (button to delete history)
- [x] T042 [US3] Handle session persistence across page navigation (React state + localStorage)

**Checkpoint**: All three user stories should now be independently functional with persistent chat history

---

## Phase 6: User Story 4 - Global Chatbot Integration (Priority: P4)

**Goal**: Ensure chatbot icon appears on every Docusaurus page and integrates seamlessly with the site theme

**Independent Test**:
1. Navigate to homepage
2. Verify chatbot icon appears in bottom-right corner
3. Navigate to each of the 6 chapter pages
4. Verify chatbot icon appears on all pages
5. Test on mobile and desktop
6. Verify chat modal works on all pages

### Implementation for User Story 4

- [x] T043 [US4] Integrate chatbot globally in website/src/theme/Root.tsx (wrap children with chatbot components)
- [x] T044 [US4] Import and use ChatbotIcon in Root.tsx
- [x] T045 [US4] Import and use ChatbotModal in Root.tsx
- [x] T046 [US4] Connect useChatbot hook state to modal props
- [x] T047 [US4] Add responsive CSS for chatbot icon (fixed position, z-index)
- [x] T048 [US4] Add responsive CSS for chatbot modal (mobile + desktop layouts)
- [x] T049 [US4] Test chatbot on all 6 chapter pages (Chapter 1-6)

**Checkpoint**: Chatbot should now appear globally and work seamlessly across all pages

---

## Phase 7: Polish & Deployment

**Purpose**: Production deployment and documentation improvements

- [x] T050 [P] Create backend/railway.json for Railway deployment configuration
- [x] T051 [P] Create backend/nixpacks.toml for build configuration
- [x] T052 [P] Create backend/Procfile for Railway start command
- [x] T053 [P] Create DEPLOYMENT.md with step-by-step deployment guide
- [x] T054 [P] Create QUICKSTART.md with 15-minute local setup guide
- [x] T055 [P] Update backend/README.md with ingestion instructions
- [x] T056 Add API URL environment variable support in website (.env with REACT_APP_API_URL)
- [x] T057 Document Qdrant Cloud setup in DEPLOYMENT.md
- [x] T058 Document Neon PostgreSQL setup in DEPLOYMENT.md
- [x] T059 Document OpenAI API key setup in DEPLOYMENT.md
- [x] T060 Create example .env file with all required variables
- [x] T061 Add error handling for missing environment variables in backend/app/config.py
- [x] T062 Add health check validations for all services in backend/app/main.py startup
- [x] T063 Add CORS configuration for production domain in backend/app/main.py
- [x] T064 Document cost estimates in DEPLOYMENT.md
- [x] T065 Document monitoring and troubleshooting in DEPLOYMENT.md

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
- **User Stories (Phase 3-6)**: All depend on Foundational phase completion
  - US1 (Ask General Question): Can start after Foundational - No dependencies on other stories
  - US2 (Ask About Selected Text): Can start after Foundational - Extends US1 but independently testable
  - US3 (Navigate with Chat History): Can start after Foundational - Enhances US1/US2 but independently testable
  - US4 (Global Integration): Can start after Foundational - Integrates all stories but independently testable
- **Polish (Phase 7)**: Depends on all user stories being complete

### User Story Dependencies

- **User Story 1 (P1) - Ask General Question**:
  - Requires: Foundational phase complete
  - Provides: Full RAG pipeline (document ingestion, vector search, answer generation)
  - Independent: Yes - Can be tested alone

- **User Story 2 (P2) - Ask About Selected Text**:
  - Requires: Foundational phase complete
  - Extends: US1 (reuses API structure)
  - Independent: Yes - Adds new query mode, doesn't break US1

- **User Story 3 (P3) - Navigate with Chat History**:
  - Requires: Foundational phase complete
  - Enhances: US1, US2 (adds persistence)
  - Independent: Yes - Chat works without history, history enhances experience

- **User Story 4 (P4) - Global Integration**:
  - Requires: Foundational phase complete
  - Integrates: US1, US2, US3
  - Independent: Yes - Chatbot works per-page, global makes it accessible everywhere

### Within Each User Story

- US1: Ingestion ‚Üí Backend API ‚Üí Frontend Integration ‚Üí Testing
- US2: Schema Update ‚Üí Backend Logic ‚Üí Frontend Detection ‚Üí Testing
- US3: Session Management ‚Üí History Storage ‚Üí History Loading ‚Üí Testing
- US4: Theme Integration ‚Üí Global Mounting ‚Üí Responsive CSS ‚Üí Testing

### Parallel Opportunities

**Phase 1 (Setup)**: All tasks [P] can run in parallel
- T003, T004, T005 (documentation and config files)

**Phase 2 (Foundational)**: Many tasks [P] can run in parallel
- T008, T009, T010 (three service files)
- T015, T016 (two frontend components)

**Phase 3 (US1)**: Several tasks [P] can run in parallel
- T017, T018 (ingestion setup tasks)

**Phase 7 (Polish)**: Most tasks [P] can run in parallel
- T050, T051, T052 (deployment configs)
- T053, T054, T055 (documentation files)

**Cross-Story**: Once Foundational is complete, all user stories can be worked on in parallel by different developers

---

## Parallel Example: Foundational Phase

```bash
# Launch all service implementations together:
Task: "Implement backend/app/services/openai_service.py"
Task: "Implement backend/app/services/qdrant_service.py"
Task: "Implement backend/app/services/neon_service.py"

# Launch all frontend components together:
Task: "Create website/src/components/ChatbotIcon.tsx"
Task: "Create website/src/components/ChatbotModal.tsx"
```

## Parallel Example: User Story 1

```bash
# Launch ingestion tasks together:
Task: "Create backend/app/ingest_textbook.py"
Task: "Implement markdown parsing in ingest_textbook.py"
```

---

## Implementation Strategy

### MVP First (User Story 1 Only)

1. ‚úÖ Complete Phase 1: Setup
2. ‚úÖ Complete Phase 2: Foundational (CRITICAL - blocks all stories)
3. ‚úÖ Complete Phase 3: User Story 1 (Ask General Question)
4. ‚úÖ **VALIDATE**: Test US1 independently - students can ask questions and get answers
5. Ready to deploy MVP

### Incremental Delivery

1. ‚úÖ Setup + Foundational ‚Üí Foundation ready
2. ‚úÖ Add User Story 1 ‚Üí Test independently ‚Üí **MVP Ready!**
3. ‚úÖ Add User Story 2 ‚Üí Test independently ‚Üí Selected-text mode works
4. ‚úÖ Add User Story 3 ‚Üí Test independently ‚Üí Chat history persists
5. ‚úÖ Add User Story 4 ‚Üí Test independently ‚Üí Chatbot globally integrated
6. üìã Deploy ‚Üí Follow DEPLOYMENT.md guide
7. Each story adds value without breaking previous stories

### Parallel Team Strategy

With multiple developers:

1. ‚úÖ Team completes Setup + Foundational together
2. Once Foundational is done:
   - Developer A: User Story 1 (Full-book query)
   - Developer B: User Story 2 (Selected-text query)
   - Developer C: User Story 3 (Chat history)
   - Developer D: User Story 4 (Global integration)
3. Stories complete and integrate independently

---

## Implementation Status

### Completed Phases

‚úÖ **Phase 1: Setup** (5 tasks) - Project structure and configuration
‚úÖ **Phase 2: Foundational** (11 tasks) - Core services and components
‚úÖ **Phase 3: User Story 1** (13 tasks) - Full-book query mode with RAG pipeline
‚úÖ **Phase 4: User Story 2** (8 tasks) - Selected-text query mode
‚úÖ **Phase 5: User Story 3** (5 tasks) - Chat history persistence
‚úÖ **Phase 6: User Story 4** (7 tasks) - Global chatbot integration
‚úÖ **Phase 7: Polish** (16 tasks) - Deployment configuration and documentation

### Total Task Count

- **Total Tasks**: 65 tasks
- **Setup**: 5 tasks
- **Foundational**: 11 tasks
- **User Story 1**: 13 tasks
- **User Story 2**: 8 tasks
- **User Story 3**: 5 tasks
- **User Story 4**: 7 tasks
- **Polish**: 16 tasks

### Parallel Opportunities Identified

- Phase 1: 3 parallel tasks (documentation)
- Phase 2: 5 parallel tasks (services + components)
- Phase 3: 2 parallel tasks (ingestion)
- Phase 7: 13 parallel tasks (deployment + docs)
- **Total Parallel Tasks**: 23 tasks (35% of all tasks)

### MVP Scope

**Minimum Viable Product** = Setup + Foundational + User Story 1
- **Tasks**: 29 tasks (45% of total)
- **Functionality**: Students can ask questions about textbook and get answers with sources
- **Value**: Core RAG chatbot working end-to-end

### Next Steps

1. üìã **Deploy Backend to Railway**:
   - Follow DEPLOYMENT.md Section "Step-by-Step Deployment"
   - Set up environment variables
   - Deploy FastAPI backend

2. üìã **Initialize Databases**:
   - Run schema.sql in Neon SQL Editor
   - Create Qdrant collection (auto-created on first ingest)

3. üìã **Ingest Textbook Content**:
   ```bash
   cd backend
   python -m app.ingest_textbook
   ```

4. üìã **Update Frontend**:
   - Add REACT_APP_API_URL to Vercel environment variables
   - Redeploy frontend

5. üìã **Test End-to-End**:
   - Verify US1: Ask "What is Physical AI?" ‚Üí Get answer with sources
   - Verify US2: Highlight text ‚Üí Ask question ‚Üí Get context-specific answer
   - Verify US3: Navigate pages ‚Üí Chat history persists
   - Verify US4: Chatbot appears on all 6 chapter pages

---

## Notes

- ‚úÖ All tasks completed - implementation finished before task documentation
- [P] tasks = different files, no dependencies - can run in parallel
- [Story] label maps task to specific user story for traceability
- Each user story is independently completable and testable
- Implementation followed incremental delivery strategy
- All 4 user stories implemented and integrated
- Ready for deployment following DEPLOYMENT.md guide
- No tests included (not explicitly requested in spec)
- All acceptance criteria from spec.md met
